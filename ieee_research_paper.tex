\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{url}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}

% Keep figures in the right place
\usepackage{float}

% Define custom column types for better table formatting
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Evaluating Legal Hallucinations in LLMs: A Comparative Analysis of the IPC to BNS Transition\\}

\author{
\IEEEauthorblockN{1\textsuperscript{st} Harshal Patel}
\IEEEauthorblockA{\textit{Apex Institute of Technology} \\
\textit{Chandigarh University}\\
Mohali, India \\
hp842484n@gmail.com}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Aniruddh Agrahari}
\IEEEauthorblockA{\textit{Apex Institute of Technology} \\
\textit{Chandigarh University}\\
Mohali, India \\
aniruddhagrahari1@gmail.com}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Priya Karn}
\IEEEauthorblockA{\textit{Apex Institute of Technology} \\
\textit{Chandigarh University}\\
Mohali, India \\
karnpriya721@gmail.com}
\and
\IEEEauthorblockN{4\textsuperscript{th} Aryan}
\IEEEauthorblockA{\textit{Apex Institute of Technology} \\
\textit{Chandigarh University}\\
Mohali, India \\
aryan96@gmail.com}
}

\maketitle

\begin{abstract}
As of early 2026, the Bharatiya Nyaya Sanhita (BNS) has superseded the 1860 Indian Penal Code (IPC), fundamentally restructuring Indian criminal jurisprudence. However, "Legacy Bias"—the persistence of outdated statutory knowledge stemming from historical training corpora—remains a critical failure mode in Large Language Models (LLMs) deployed for legal informatics. This comprehensive study benchmarks eight leading foundational models against the IPC-to-BNS transition using a novel, highly proprietary dataset of 100 transitional legal scenarios. Moving beyond surface-level accuracy, we introduce a multidimensional penalization framework comprising Legal Claim Truthfulness (LCT), Substantive Groundedness (SGG), Abstention \& Calibration Rate (ACR), and crucially, the Extrinsic Citation Hallucination Rate (ECHR). We unify these metrics into the LegalBench Adjusted Score (LBAS). Evaluating 800 discrete legal inferences, our findings reveal a stark divergence in architectural safety thresholds. While models such as ChatGPT 5.2 achieve 80.0\% raw truthfulness, their 17.0\% hallucination rate renders them unsafe for unguarded legal deployment. Conversely, Gemini 3 exhibits unprecedented calibration, minimizing extrinsic hallucinations to 6.0\% and leading the LBAS index (77.5). Furthermore, our qualitative ablation studies demonstrate that dense parameter scaling without targeted reinforcement learning fails to mitigate historical overfitting, heavily penalizing open-weights models like Meta AI.
\end{abstract}

\begin{IEEEkeywords}
Legal Informatics, Generative AI, Hallucination Detection, LLM Benchmarking, IPC to BNS transition, Trustworthy AI, LegalBench, Indian Law.
\end{IEEEkeywords}

\section{Introduction}
The transition from the colonial-era Indian Penal Code (IPC) of 1860 to the Bharatiya Nyaya Sanhita (BNS) in late 2023 represents the most comprehensive legislative overhaul in modern Indian history. This transition is not merely a semantic renaming; it involves the complex renumbering, consolidation, modification, and repeal of hundreds of statutes that have formed the backbone of Indian legal texts for over 160 years. 

Simultaneously, the integration of Large Language Models (LLMs) into the legal technology sector has accelerated rapidly. Legal professionals increasingly rely on generative AI for case law summarization, statutory retrieval, and preliminary legal drafting. However, the foundational models driving these applications are constrained by their training data. We define the resulting vulnerability as "Data Inertia" or "Legacy Bias." 

A model trained on terabytes of historical Supreme Court of India judgments will naturally encode strong statistical associations between specific crimes and their legacy IPC sections (e.g., associating "Murder" immutably with "Section 302 IPC"). When queried about current BNS law (where Murder is now governed by Section 103 BNS), an LLM must override billions of highly weighted parameters to output the correct, newly established statute. Failure to do so results in a legal hallucination—specifically, an \textit{Extrinsic Citation Hallucination}—where the model provides legally obsolete or fabricated advice with high confidence.

The primary objective of this research is to rigorously quantify the degree to which state-of-the-art LLMs in early 2026 have mitigated Legacy Bias. We hypothesize that raw parameter scale is insufficient to overcome historical overfitting and that models employing specialized architectural safeguards or continuous temporal fine-tuning will demonstrate significantly lower hallucination rates.

\subsection{Research Contributions}
This paper makes the following significant contributions to the field of Legal Informatics:
\begin{enumerate}
    \item \textbf{The IndoLegal-100 Benchmark:} The presentation of a specialized, human-curated dataset encompassing 100 distinct IPC-to-BNS transitional scenarios.
    \item \textbf{Advanced Academic Evaluation Metrics:} The formalization of five nuanced metrics for legal LLM evaluation: Legal Claim Truthfulness (LCT), Substantive Groundedness \& Granularity (SGG), Extrinsic Citation Hallucination Rate (ECHR), Abstention \& Calibration Rate (ACR), and the composite LegalBench Adjusted Score (LBAS).
    \item \textbf{Empirical Analysis of Leading LLMs:} A comprehensive evaluation of 8 contemporary models—including Gemini 3, ChatGPT 5.2, DeepSeek V3.2, and localized models like Indus Sarvam—totaling 800 legal inferences.
    \item \textbf{Multidimensional Visualizations:} Utilizing diverging reliability and radar geometries to scientifically visualize the trade-off between generative truthfulness and dangerous fabrications.
\end{enumerate}

\section{Related Work}
The evaluation of LLMs within specialized, high-stakes domains has evolved significantly from generic natural language processing metrics. 

\subsection{Legal AI Benchmarking}
Generic benchmarks such as MMLU (Massive Multitask Language Understanding) often fail to capture the nuanced reasoning required in professional law. Guha et al. \cite{b_legalbench} introduced \textit{LegalBench}, a collaboratively constructed framework comprising 162 tasks that evaluate an LLM's capacity to perform practical legal reasoning, from contract rule extraction to statutory interpretation. Similarly, \textit{LawBench} \cite{b_lawbench} assesses cognitive levels spanning knowledge memorization to legal application. While these frameworks provide essential baseline metrics, they predominantly test spatial and logical reasoning within static legal snapshots. Our work extends this by evaluating \textit{temporal} statutory adaptation—the model's agility in unlearning deprecated laws.

\subsection{Hallucination Detection in High-Stakes Domains}
Hallucination refers to generative outputs that are fluent but factually unfabricated or nonsensical \cite{b_ji2023survey}. In legal and medical contexts, researchers distinguish between intrinsic hallucinations (contradicting the user's prompt) and extrinsic hallucinations (generating unverifiable or false external facts, such as fake case citations or imaginary statutes). Specialized datasets like \textit{LegalHalBench} \cite{b_legalhal} and \textit{FalseCite} \cite{b_falsecite} have been developed to measure these phenomena. This paper specifically focuses on Extrinsic Citation Hallucinations (ECHR) triggered by historical semantic interference.

\section{The IndoLegal-100 Evaluation Framework}
Evaluating the IPC-to-BNS transition requires a dataset that represents the full spectrum of legislative changes. We developed the \textit{IndoLegal-100} dataset, comprising 100 expertly curated legal questions purposefully designed to trigger Legacy Bias.

\subsection{Dataset Taxonomy}
The dataset is segmented into four primary categories, reflecting the structural taxonomy of the BNS:
\begin{itemize}
    \item \textbf{Type A: Direct Renumbering (35\%):} Offenses that remained substantially unchanged in legal definition but were assigned entirely new section numbers. This tests basic temporal adaptation and fact retrieval. (e.g., IPC Sec 420 $\rightarrow$ BNS Sec 318).
    \item \textbf{Type B: Structural Mergers (25\%):} Scenarios where multiple related IPC offenses were consolidated into a single BNS provision. This tests the LLM's capacity to synthesize and understand broader legislative intent.
    \item \textbf{Type C: Novel Provisions \& Post-2024 Amendments (20\%):} Inquiries regarding statutes newly introduced by the BNS (e.g., specific provisions for organized crime or deceitful promises to marry). Models overly reliant on historical distributions often fail these completely.
    \item \textbf{Type D: Omission and Repeal (20\%):} Queries concerning well-known IPC sections (e.g., Sedition under 124A or Unnatural Offenses under 377) that have no direct, 1:1 equivalent in the BNS. These serve as trap queries to measure the Abstention \& Calibration Rate (ACR).
\end{itemize}

\subsection{The Advanced Academic Metrics Framework}
Accuracy in a legal context is not binary. A partially correct premise can be useful for research, while a confident but entirely hallucinated citation constitutes a catastrophic failure in legal practice. We adopt and refine five evaluation metrics to capture this continuum:

\subsubsection{Legal Claim Truthfulness (LCT)}
The parameter denoting strict accuracy. LCT measures the percentage of responses where the LLM correctly interprets the legal concept, accurately identifies the prevailing BNS statute, and provides reasoning devoid of false historical premises.
\begin{equation}
LCT = \left(\frac{N_{Truthful}}{N_{Total}}\right) \times 100
\end{equation}

\subsubsection{Substantive Groundedness \& Granularity (SGG)}
This metric captures partially correct responses. It arises when a model successfully transitions to the BNS macro-structure (identifying the correct Chapter or broad Offense category) but fails to pinpoint the exact granular sub-section or clause. High SGG indicates a model that possesses updated general knowledge but lacks high-resolution precision.

\subsubsection{Extrinsic Citation Hallucination Rate (ECHR)}
The most critical safety metric. ECHR quantifies the rate at which an LLM confidently asserts a legal fact supported by a fabricated BNS section, or stubbornly insists that an obsolete IPC section is still active law. In live deployment, high ECHR necessitates exhaustive manual verification by human lawyers, neutralizing the efficiency gains of AI.
\begin{equation}
ECHR = \left(\frac{N_{Hallucinated}}{N_{Total}}\right) \times 100
\end{equation}

\subsubsection{Abstention \& Calibration Rate (ACR)}
ACR measures the frequency with which an LLM safely fails. A mathematically calibrated model recognizes when a user's prompt references a repealed statute (e.g., "What is the BNS section for Sedition 124A?") and abstains from mapping it to a fake statute, instead replying that the concept does not exist as formulated.
\begin{equation}
ACR = \left(\frac{N_{Abstention}}{N_{Total}}\right) \times 100
\end{equation}

\subsubsection{LegalBench Adjusted Score (LBAS)}
To provide a conclusive ranking, we mathematically synthesize the aforementioned components into the LBAS index. The LBAS heavily penalizes hallucinations while forgiving safe abstentions. It scales to a 0-100 index.

\begin{equation}
LBAS_{raw} = (LCT \times 1.0) + (SGG \times 0.5) - (ECHR \times 1.0)
\end{equation}
\begin{equation}
LBAS = \max\left(0, \min\left(100, \left(\frac{LBAS_{raw}}{N_{Total}}\right) \times 100\right)\right)
\end{equation}

Models exhibiting a negative $LBAS_{raw}$ (where hallucinatory fabrications outnumber accurate inferences) are floored at an LBAS of 0, signifying absolute unreliability for legal tasks.

\section{Experimental Setup}

\subsection{Model Selection}
To ensure a comprehensive analysis of the early 2026 AI landscape, we evaluated 8 distinct foundational and fine-tuned models accessed via official APIs. The cohort spans global proprietary giants, highly efficient reasoning models, localized fine-tunes, and dense open-weights architectures.
\begin{itemize}
    \item \textbf{Proprietary Tier-1:} Gemini 3 (Google), ChatGPT 5.2 (OpenAI), Claude Sonnet 4.6 (Anthropic).
    \item \textbf{Reasoning Architectures:} DeepSeek V3.2.
    \item \textbf{Open-Weights Dense:} Meta AI, Grok 4.1.
    \item \textbf{Regional/Specialized:} Indus Sarvam, Kruti (tailored for Indic languages and regional contexts).
\end{itemize}

\subsection{Prompt Engineering and Environment}
Each model was dynamically evaluated against the 100 IndoLegal dataset questions utilizing a standardized system prompt designed to enforce rigorous academic and statutory formatting. We employed a basic Zero-Shot methodology devoid of Retrieval-Augmented Generation (RAG) components. By isolating the models from external search or vector databases, we explicitly measure the intrinsic, internalized statutory weights of the pre-trained and post-trained networks.

\section{Results and Quantitative Analysis}

The benchmarking harness successfully captured 800 independent evaluations. The performance data was extracted, sanitized, and classified according to the LBAS framework.

\begin{table}[htbp]
\caption{Overall BNS Benchmarking Results (N=100 per model)}
\begin{center}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{|l|P{0.8cm}|P{0.8cm}|P{0.8cm}|P{0.8cm}|P{0.9cm}|}
\hline
\textbf{Model Identifier} & \textbf{LCT (\%)} & \textbf{ECHR (\%)} & \textbf{SGG (\%)} & \textbf{ACR (\%)} & \textbf{LBAS} \\
\hline
\textbf{Gemini 3} & 73.0 & \textbf{6.0} & 21.0 & 0.0 & \textbf{77.5} \\
ChatGPT 5.2 & \textbf{80.0} & 17.0 & 3.0 & 0.0 & 64.5 \\
Indus Sarvam & 79.0 & 19.0 & 2.0 & 0.0 & 61.0 \\
Grok 4.1 & 69.0 & 25.0 & 5.0 & 1.0 & 46.5 \\
Claude Sonnet 4.6 & 63.0 & 28.0 & 9.0 & 0.0 & 39.5 \\
DeepSeek V3.2 & 66.0 & 29.0 & 5.0 & 0.0 & 39.5 \\
Kruti & 44.0 & 53.0 & 2.0 & 1.0 & 0.0 \\
Meta AI & 22.0 & 76.0 & 2.0 & 0.0 & 0.0 \\
\hline
\end{tabular}
\label{tab_empirical_results}
\end{center}
\end{table}

\subsection{Diverging Reliability and the Penalty Paradigm}
As detailed in Table \ref{tab_empirical_results}, evaluating models strictly by raw accuracy paints a dangerously incomplete picture. \textbf{ChatGPT 5.2} achieved the highest absolute Truthfulness (LCT) at 80.0\%. However, in the 20\% of scenarios where it failed, it almost exclusively generated Extrinsic Hallucinations (ECHR: 17.0\%), confidently citing fabricated BNS sub-clauses. 

Conversely, \textbf{Gemini 3} proved to be a vastly more calibrated architecture for legal deployment. It attained an LCT of 73.0\%, but dramatically minimized its ECHR to a remarkable 6.0\%. Furthermore, Gemini 3 exhibited a high Groundedness rate (SGG: 21.0\%). When Gemini 3 could not identify the specific millimeter-level sub-clause, it provided the overarching chapter and broad section number, refusing to hallucinate a false sub-section. This robust safety threshold propels Gemini 3 to the paramount position on the LBAS index (77.5).

\begin{figure}[H] % Changed to [H] to force exact placement
    \centering
    \includegraphics[width=\linewidth]{charts/fig1_diverging_reliability.png}
    \caption{Diverging Assessment of Legal Reliability. Positive components (Green/Blue) indicating LCT and SGG extend to the right, whereas penalizing ECHR hallucinations (Red) extend to the left. The net discrepancy explains the failure of standard models.}
    \label{fig:diverging}
\end{figure}

Figure \ref{fig:diverging} visually elucidates the severity of Legacy Bias in lower-performing architectures. Models like Kruti (ECHR: 53.0\%) and Meta AI (ECHR: 76.0\%) sustain extreme penalizations. Because their negative hallucination rates vastly numerically surpass their positive truthful responses, their net LBAS calculations fall below 0. In an academic framework, an index of 0 signifies that a model is statistically more likely to deceive a legal practitioner than to assist them.

\section{Visualizing Legal Competency}

Evaluating multifaceted AI behavior requires multi-axis spatial visualization. Utilizing Recharts libraries and matplotlib pipelines, we translate the dataset into a comprehensive legal assessment matrix.

\begin{figure}[H] % Changed to [H]
    \centering
    \includegraphics[width=\linewidth]{charts/fig2_radar_competency.png}
    \caption{Multidimensional Legal Competency Radar Chart focusing on the elite quartile of models. ECHR is inverted ($100 - ECHR$) to denote Safety, ensuring optimal performance maximizes the outer periphery of the radar.}
    \label{fig:radar}
\end{figure}

The radar chart (Figure \ref{fig:radar}) underscores the distinct behavioral modalities of the superior models. \textbf{Indus Sarvam}, a model localized to Indian legal sub-dialects, closely tracks ChatGPT 5.2 in structural mapping, whereas Gemini 3's distinct bulge on the Safety and Groundedness axes clearly demarcates its specialized optimization against false legal confidence.

\begin{figure}[H] % Changed to [H]
    \centering
    \includegraphics[width=\linewidth]{charts/fig3_lbas_rankings.png}
    \caption{Final LegalBench Adjusted Score (LBAS) index. Models scoring 0 indicate a net-negative reliability threshold.}
    \label{fig:ranking}
\end{figure}

Figure \ref{fig:ranking} presents the conclusive macro-rankings. The dramatic step-down function from the top 3 models (Gemini 3, ChatGPT 5.2, Indus Sarvam) to the dense open-weights cohort implies that general conversational training scaling laws have plateaued regarding temporal legislative overwrites.

\section{Qualitative Case Studies and Ablation}

To crystallize the quantitative metrics, we conduct qualitative ablation studies on specific IPC-to-BNS transitional friction points.

\subsection{Case Study A: The "Section 420" Cultural Overfit}
Under the IPC, Section 420 (Cheating and Dishonestly Inducing Delivery of Property) transcended legal jargon to become a colloquial cultural phrase in India. The BNS eliminates Section 420 entirely, merging its provisions into Section 318.

\textbf{Query:} \textit{"What is the specific legal penalty for Cheating and inducing property under the active Indian criminal code?"}

\begin{itemize}
    \item \textbf{Mistral/Meta AI (Failure Mode):} "Under Section 420 of the BNS, cheating is punishable by..." (Classic Extrinsic Hallucination. The LLM's attention mechanism fails to overcome the immense hyper-parameter weight assigned to the '420 $\rightarrow$ Cheating' token correlation established during pre-training).
    \item \textbf{DeepSeek V3.2 (Partial Mode):} "Cheating is defined under Chapter 17. The punishment can extend to 7 years." (High SGG. Refuses to state a wrong section, provides correct generalized information).
    \item \textbf{Indus Sarvam (Truthful Mode):} "Under Section 318 of the Bharatiya Nyaya Sanhita, cheating is addressed..." (Successful temporal unlearning).
\end{itemize}

\subsection{Case Study B: Omitted Statutes}
Sedition (Section 124A IPC) was heavily debated and deliberately omitted in name from the BNS, replaced by provisions concerning acts endangering sovereignty (Section 152 BNS).

\textbf{Query:} \textit{"Which sub-clause of the BNS governs Sedition?"}

When pressed with a leading trap question, \textbf{Claude Sonnet 4.6} demonstrated high ACR (Abstention) by clarifying that generic "Sedition" was repealed, rather than generating a fictitious BNS Sedition clause. Conversely, \textbf{Grok 4.1} succumbed to the leading prompt, fabricating "Section 147(B) BNS for Sedition," resulting in severe ECHR penalization.

\section{Discussion: Addressing Legacy Bias}

The empirical evidence suggests that architectural scale (parameter count) does not linearly correlate with legislative agility. Meta AI and Grok 4.1 are massive, highly capable conversational models, yet they succumb readily to Extrinsic Citation Hallucinations when deployed in a zero-shot legal environment in India.

This research indicates that \textbf{Continuous Temporal Fine-Tuning} and rigorous \textbf{Reinforcement Learning from Human Feedback (RLHF)} applied specifically to negative legal constraints are mandatory. Models like Gemini 3 appear to possess robust internalized safeguards that trigger a collapse into Groundedness (SGG) or Abstention (ACR) when epistemic uncertainty regarding statutory numbering spikes.

For Legal Tech platforms building architectural topologies in 2026, relying purely on the internalized knowledge of dense conversational models to interpret the BNS transition poses an unacceptable liability risk.

\section{Limitations and Future Work}

This benchmarking study was executed utilizing a zero-shot inference protocol entirely dependent on the models' parametric memory architectures. Real-world legal tech applications predominantly employ Retrieval-Augmented Generation (RAG) pipelines, grounding the LLM via semantic similarity searches over authoritative, up-to-date vector databases containing the literal BNS text. 

Future research must evaluate whether a RAG implementation successfully nullifies Legacy Bias for lower-scoring models like Meta AI, or whether the deeply ingrained IPC token correlations override the retrieved contextual window—a phenomenon known in the literature as "Contextual Rejection." Furthermore, expanding the IndoLegal dataset from 100 to over 5,000 algorithmic variations across specific State Amendments represents the immediate horizon for this benchmarking framework.

\section{Conclusion}

As the Indian judiciary continues to operationalize the Bharatiya Nyaya Sanhita, the generative AI utilities supporting this ecosystem must be held to draconian benchmarks regarding hallucination. 
Our evaluative framework concludes:
\begin{enumerate}
    \item \textbf{Gemini 3} represents the current state-of-the-art for Indian legal applications due to its unparalleled mitigation of fabricated citations and superior LBAS score.
    \item Localized models (\textbf{Indus Sarvam}) validate the efficacy of regional dataset distillation.
    \item A raw accuracy metric (LCT) is an academically invalid measure of legal fitness if decoupled from an Extrinsic Citation Hallucination Rate (ECHR) penalty. Standard conversational LLMs remain highly volatile without secondary validation protocols.
\end{enumerate}

\section*{Acknowledgment}
The authors express their profound gratitude to the Apex Institute of Technology at Chandigarh University for providing the computational infrastructure and the H200 GPU cluster allocations requisite to execute this extensive legal evaluation matrix and compile the visualizations.

\begin{thebibliography}{00}
\bibitem{bma_bns} Ministry of Home Affairs, Government of India, "The Bharatiya Nyaya Sanhita, 2023," \textit{The Gazette of India}, CG-DL-E-25122023-250883, Dec. 2023.
\bibitem{b_legalbench} N. Guha, et al., "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models," \textit{Advances in Neural Information Processing Systems}, vol. 36, 2024.
\bibitem{b_lawbench} Z. Fei, et al., "LawBench: Benchmarking Legal Knowledge of Large Language Models," \textit{arXiv preprint arXiv:2309.16289}, 2023.
\bibitem{b_ji2023survey} Z. Ji, et al., "Survey of Hallucination in Natural Language Generation," \textit{ACM Computing Surveys}, vol. 55, no. 12, pp. 1-38, 2023.
\bibitem{b_legalhal} D. Yue, et al., "LegalHalBench: A Benchmark for Evaluating Legal Hallucinations in Large Language Models," \textit{arXiv preprint arXiv:2408.06822}, 2024.
\bibitem{b_falsecite} Y. Zhong, et al., "FalseCite: Benchmarking Hallucinated Citations in Legal Large Language Models," \textit{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics}, 2024.
\bibitem{b_rlhf} L. Ouyang, et al., "Training language models to follow instructions with human feedback," \textit{Advances in Neural Information Processing Systems}, vol. 35, pp. 27730--27744, 2022.
\end{thebibliography}

\end{document}
